<html>
<head>
<title>Web Crawler with JavaScript— These Easy Steps Help Me Get Medium Articles’ Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用JavaScript的网络爬虫——这些简单的步骤帮助我获得中等文章的数据</h1>
<blockquote>原文：<a href="https://javascript.plainenglish.io/web-crawler-javascript-these-easy-steps-help-me-get-medium-articles-data-3b9e9e76594?source=collection_archive---------6-----------------------#2022-12-12">https://javascript.plainenglish.io/web-crawler-javascript-these-easy-steps-help-me-get-medium-articles-data-3b9e9e76594?source=collection_archive---------6-----------------------#2022-12-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="819f" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">检索文章的有价值信息以供进一步分析</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/52bcf32a6e8275d09f9b67c250f37d8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jjodCDOhujicEHc4"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo by <a class="ae kv" href="https://unsplash.com/@kmuza?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Carlos Muza</a> on <a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="7200" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">数据分析让我们深入了解这个领域。然而，官方并不总是能够获得这些数据。在这种情况下，抓取网站是一种替代解决方案。本文旨在为读者提供从Medium网站抓取数据的分步说明。</p><p id="aaa7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最终，我们将得到一个类似这样的数据集:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ls lt l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><a class="ae kv" href="https://gist.github.com/ddkhoa/6197a03aa7b8850fb23824e128de1742" rel="noopener ugc nofollow" target="_blank">Example dataset</a></figcaption></figure><p id="52bc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可以运行以下分析:</p><ul class=""><li id="c8d3" class="lu lv iq ky b kz la lc ld lf lw lj lx ln ly lr lz ma mb mc bi translated">回答以下关于平台的问题:作家什么时候发表作品？谁是最好的作者？帕累托原理适用于中等吗？…</li><li id="7222" class="lu lv iq ky b kz md lc me lf mf lj mg ln mh lr lz ma mb mc bi translated">探究数据中的关系:关注人数和鼓掌次数之间是否存在相关性？中等会员的文章比非中等会员的文章更受关注吗？…</li></ul><p id="344d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">例如，下面是我对180 000篇中型文章的分析:</p><div class="mi mj gp gr mk ml"><a href="https://medium.com/@ddkhoa.blogging/of-curiosity-i-analyzed-180-000-articles-on-medium-53f359ecdecc" rel="noopener follow" target="_blank"><div class="mm ab fo"><div class="mn ab mo cl cj mp"><h2 class="bd ir gy z fp mq fr fs mr fu fw ip bi translated">出于好奇，我分析了大约18万篇关于媒体的文章</h2><div class="ms l"><h3 class="bd b gy z fp mq fr fs mr fu fw dk translated">了解领先的博客平台之一</h3></div><div class="mt l"><p class="bd b dl z fp mq fr fs mr fu fw dk translated">medium.com</p></div></div><div class="mu l"><div class="mv l mw mx my mu mz kp ml"/></div></div></a></div><p id="d153" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本教程中，我们使用自底向上的方法构建一个爬虫。首先，我们来看看一个典型的中型网页。然后，我们将看看如何收集大量文章来创建数据集。每个步骤都包含代码。</p><p id="0550" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">开始吧！</p><h1 id="2b8f" class="na nb iq bd nc nd ne nf ng nh ni nj nk jw nl jx nm jz nn ka no kc np kd nq nr bi translated">1 —从1篇文章中获取信息</h1><h2 id="f35d" class="ns nb iq bd nc nt nu dn ng nv nw dp nk lf nx ny nm lj nz oa no ln ob oc nq od bi translated"><strong class="ak"> 1.1 —浏览页面并找到数据</strong></h2><p id="1684" class="pw-post-body-paragraph kw kx iq ky b kz oe jr lb lc of ju le lf og lh li lj oh ll lm ln oi lp lq lr ij bi translated">以一个典型的中型职位，打开它在一个新的标签，然后打开控制台标签。</p><div class="mi mj gp gr mk ml"><a href="https://medium.com/@ddkhoa.blogging/being-a-junior-developer-taught-me-the-important-life-lesson-8ad73582d912" rel="noopener follow" target="_blank"><div class="mm ab fo"><div class="mn ab mo cl cj mp"><h2 class="bd ir gy z fp mq fr fs mr fu fw ip bi translated">作为一名初级开发人员，我学到了人生重要的一课</h2><div class="ms l"><h3 class="bd b gy z fp mq fr fs mr fu fw dk translated">四年前，我毕业的时候，我知道我是大三。现在，我明白为什么我是这样的人。这给了我…</h3></div><div class="mt l"><p class="bd b dl z fp mq fr fs mr fu fw dk translated">medium.com</p></div></div><div class="mu l"><div class="oj l mw mx my mu mz kp ml"/></div></div></a></div><p id="1ea0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们看到了什么？</p><ul class=""><li id="5845" class="lu lv iq ky b kz la lc ld lf lw lj lx ln ly lr lz ma mb mc bi translated">URL的最后一部分是文章的id。我们可以忽略URL中的其他部分。这个网址会给我们相同的页面:<a class="ae kv" href="https://medium.com/p/8ad73582d912" rel="noopener">https://medium.com/p/8ad73582d912</a></li><li id="a35c" class="lu lv iq ky b kz md lc me lf mf lj mg ln mh lr lz ma mb mc bi translated">在控制台中键入<code class="fe ok ol om on b">__APOLLO_STATE__</code>并按回车键。您将看到关于文章的所有信息。这次我们走运了。不是所有的网站都将页面数据存储在一个可见的变量中。在这种情况下，我们必须单独选取页面上的元素来提取数据。</li></ul><h2 id="e95a" class="ns nb iq bd nc nt nu dn ng nv nw dp nk lf nx ny nm lj nz oa no ln ob oc nq od bi translated"><strong class="ak"> 1.2 —考虑实施选择和影响</strong></h2><p id="3f8a" class="pw-post-body-paragraph kw kx iq ky b kz oe jr lb lc of ju le lf og lh li lj oh ll lm ln oi lp lq lr ij bi translated">现在我们有两个提取数据的选项</p><p id="81f7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">选项1 </strong>:访问页面，将<code class="fe ok ol om on b">__APOLLO_STATE__</code>变量的整个值保存到本地文件。然后，从中提取信息。</p><p id="d60c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">选项2 </strong>:访问页面，获取值<code class="fe ok ol om on b">__APOLLO_STATE__</code>变量，然后只提取必要的数据并保存到本地文件。</p><p id="fab3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第一个选项会产生一个额外的大文件。然而，它有一个明显的优势:如果我们需要更多的信息，我们可以从本地文件中提取，而不是重新访问页面，这必然会更慢。我选择第一个选项。</p><h2 id="93cb" class="ns nb iq bd nc nt nu dn ng nv nw dp nk lf nx ny nm lj nz oa no ln ob oc nq od bi translated"><strong class="ak"> 1.3 —编码</strong></h2><p id="6edb" class="pw-post-body-paragraph kw kx iq ky b kz oe jr lb lc of ju le lf og lh li lj oh ll lm ln oi lp lq lr ij bi translated">这是一项简单的任务。我们首先需要下载页面。然后，我们使用<code class="fe ok ol om on b"><a class="ae kv" href="https://www.npmjs.com/package/node-html-parser" rel="noopener ugc nofollow" target="_blank">node-html-parser</a></code>库来解析结果。然后，我们可以抓取包含变量<code class="fe ok ol om on b">__APOLLO_STATE__</code>的元素。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ls lt l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Get __APOLLO_STATE__ variable from the page</figcaption></figure><p id="0118" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，我们从变量<code class="fe ok ol om on b">__APOLLO_STATE__</code>中提取必要的信息。我邀请你检查变量结构。它会帮助你理解下面的代码。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ls lt l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Extract information from __APOLLO_STATE__ variable</figcaption></figure><p id="472d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，我们添加两个实用函数来读取和写入CSV文件的数据。我用<code class="fe ok ol om on b"><a class="ae kv" href="https://www.npmjs.com/package/csv-stringify" rel="noopener ugc nofollow" target="_blank">csv-stringify</a></code>写数据，用<code class="fe ok ol om on b"><a class="ae kv" href="https://www.npmjs.com/package/csv-parse" rel="noopener ugc nofollow" target="_blank">csv-parse</a></code>从CSV文件中读取数据。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ls lt l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Helper functions to read/write data.</figcaption></figure><p id="0bb0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">小纸条。我花了1个小时弄清楚为什么<code class="fe ok ol om on b">writeToCSV</code>函数完成了，而没有运行“finish”事件中的块。</p><p id="295c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">永远不要忘记结束流！</strong> <code class="fe ok ol om on b">stringifier.end()</code></p><p id="1b65" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，我们可以结合上面的功能来创建爬虫的第一个工作版本。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ls lt l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">The pipeline.</figcaption></figure><p id="d2f0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">步骤1的恢复</strong></p><p id="60c3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这一步中，我们从URL中提取了一篇中型文章所需的数据。恭喜你！</p><p id="1506" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在管道代码中，我将变量<code class="fe ok ol om on b">urls</code>声明为一个数组，尽管它只有一个元素。我们进入下一步:获取文章的URL列表，以提供给<code class="fe ok ol om on b">urls</code>数组。</p><h1 id="df6d" class="na nb iq bd nc nd ne nf ng nh ni nj nk jw nl jx nm jz nn ka no kc np kd nq nr bi translated"><strong class="ak"> 2 —获取文章列表</strong></h1><p id="9bc0" class="pw-post-body-paragraph kw kx iq ky b kz oe jr lb lc of ju le lf og lh li lj oh ll lm ln oi lp lq lr ij bi translated">在这一步中，我们将得到一个URL列表，这是上一步的输入。我们有不同的方法来得到这个列表。</p><h2 id="e332" class="ns nb iq bd nc nt nu dn ng nv nw dp nk lf nx ny nm lj nz oa no ln ob oc nq od bi translated"><strong class="ak"> 2.1 —考虑实施选择和影响</strong></h2><p id="1062" class="pw-post-body-paragraph kw kx iq ky b kz oe jr lb lc of ju le lf og lh li lj oh ll lm ln oi lp lq lr ij bi translated"><strong class="ky ir">选项1 </strong> : <strong class="ky ir">使用可用的数据集</strong></p><p id="d760" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以搜索可用的数据集。Kaggle是数据科学领域的一个热门网站。它有许多不同领域的数据集。下面是我在Kaggle上搜索中型文章数据的结果。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oo"><img src="../Images/8d8b8ec8f38e1ba43a9b1989fff8550e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5AWUZiC0WKVgfr3kKuRaMA.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Medium article dataset on <a class="ae kv" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank">Kaggle</a>.</figcaption></figure><p id="86a7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">选项二</strong> : <strong class="ky ir">通过媒体站点地图获取文章</strong></p><p id="b9ce" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Medium和其他网站一样，使用站点地图来索引其内容。这里有一个例子:</p><blockquote class="op oq or"><p id="fb6a" class="kw kx os ky b kz la jr lb lc ld ju le ot lg lh li ou lk ll lm ov lo lp lq lr ij bi translated"><a class="ae kv" href="https://medium.com/sitemap/posts/2022/posts-2022-11-12.xml" rel="noopener">https://medium.com/sitemap/posts/2022/posts-2022-11-12.xml</a></p></blockquote><p id="1162" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">网站地图包含2022年11月12日发表的文章。我们可以实现一个函数来获取某个日期或某个时间段的文章的URL。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ow"><img src="../Images/60890099af7ac6ebc9c0ab3130ba73d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kUKBx3uHKJ6t0EJ4r-PWfw.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Medium sitemap structure</figcaption></figure><p id="21ac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">选项3 </strong> : <strong class="ky ir">从出版物存档页面</strong>获取文章</p><p id="8cfd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">每个出版物还有一个存档页面，上面有所有发表的文章。比如JavaScript的存档页面，说白了就是https://javascript.plainenglish.io/archive<a class="ae kv" rel="noopener ugc nofollow" target="_blank" href="https://javascript.plainenglish.io/archive"/>。</p><p id="b80d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以实现一个函数来获取存档页面，然后获取URL。</p><p id="c473" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要选择一个选项，我们<strong class="ky ir">必须</strong>考虑数据集在未来将如何被使用。每个解决方案都会产生一个具有独特特征的数据集。如果我们使用<a class="ae kv" href="https://www.kaggle.com/datasets/fabiochiusano/medium-articles" rel="noopener ugc nofollow" target="_blank">这个Kaggle数据集</a>，我们应该意识到数据并不是随机分散在时间上的。我们只接收选项2下在Medium.com上发表的文章，不接收在其他域名上发表的文章。当我们只从特定的出版物中收集数据时，选项3是相反的情况。如果您使用选项2或选项3对数据进行爬网，并且您不是中级成员，您将无法获得整篇文章的内容。</p><p id="1945" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://medium.com/@ddkhoa.blogging/of-curiosity-i-analyzed-180-000-articles-on-medium-53f359ecdecc" rel="noopener">在我的分析</a>中，我使用了包含来自Kaggle的大约195，000篇文章的数据集。在本教程中，我将向你展示如何使用sitemap页面获得中型文章。</p><h2 id="1fc9" class="ns nb iq bd nc nt nu dn ng nv nw dp nk lf nx ny nm lj nz oa no ln ob oc nq od bi translated">2.2 —编码</h2><p id="8e62" class="pw-post-body-paragraph kw kx iq ky b kz oe jr lb lc of ju le lf og lh li lj oh ll lm ln oi lp lq lr ij bi translated">我们将实现两个函数。第一个将获得某一天的URL。第二个函数将根据第一个函数获取一段时间内的URL。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ls lt l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Extract articles’ URLs from a sitemap</figcaption></figure><p id="38bc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了获取一段时间内的数据，我们生成一个包含日期在<code class="fe ok ol om on b">startDate</code>和<code class="fe ok ol om on b">endDate</code>之间的数组。接下来，我们调用上面的函数来获取数组中每个日期的数据，然后将它们组合成最终结果。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ls lt l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Extract articles’ URLs between 2 dates</figcaption></figure><p id="8744" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，我们将两个步骤的结果结合起来，创建一个管道，从给定时期发表的媒体文章中提取数据。</p><p id="0174" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有一点需要注意，我们不能使用有数千个元素的数组<code class="fe ok ol om on b">urls</code>然后调用<code class="fe ok ol om on b"><em class="os">Promise</em>.all(urls.map(<em class="os">item</em> =&gt; getMediumArticleDatadump(<em class="os">item</em>)))</code>。你可能会被禁止进入该域，因为滥用了速率限制。否则，服务器也无法正常响应。我们将按块处理。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ls lt l"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Extract Medium data in a given period.</figcaption></figure><p id="9324" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">每天都有许多文章发表在媒体上。因此，代码将需要一些时间来完成，这显然取决于机器的容量。</p><p id="01c5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了简单起见，我已经在这里完成了我的教程。当然，还有许多改进的机会。这里有几个例子；这不是一个详尽的列表。</p><ul class=""><li id="3c5d" class="lu lv iq ky b kz la lc ld lf lw lj lx ln ly lr lz ma mb mc bi translated">将获取代码URL的步骤与下载和提取数据的步骤分开。例如，如果您想提取整个月的中等数据，您将有很多URL。所以，最好创建一个从<code class="fe ok ol om on b">csv</code>文件中读取<code class="fe ok ol om on b">urls</code>的函数。您可以逐步处理数据。</li><li id="80a7" class="lu lv iq ky b kz md lc me lf mf lj mg ln mh lr lz ma mb mc bi translated">构建CLI。CLI可以将开始日期和结束日期作为参数，然后运行crawler。</li><li id="59bf" class="lu lv iq ky b kz md lc me lf mf lj mg ln mh lr lz ma mb mc bi translated">去云吧！您可以将代码打包到一个容器中，然后在云上运行。</li></ul></div><div class="ab cl ox oy hu oz" role="separator"><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc"/></div><div class="ij ik il im in"><h1 id="1af2" class="na nb iq bd nc nd pe nf ng nh pf nj nk jw pg jx nm jz ph ka no kc pi kd nq nr bi translated">简历</h1><p id="2b31" class="pw-post-body-paragraph kw kx iq ky b kz oe jr lb lc of ju le lf og lh li lj oh ll lm ln oi lp lq lr ij bi translated">在本文中，我们使用Node.js构建了一个爬虫来从Medium中提取文章数据。</p><ul class=""><li id="5988" class="lu lv iq ky b kz la lc ld lf lw lj lx ln ly lr lz ma mb mc bi translated"><strong class="ky ir">利用</strong> <code class="fe ok ol om on b"><strong class="ky ir">csv-stringify</strong></code> <strong class="ky ir">和</strong> <code class="fe ok ol om on b"><strong class="ky ir">csv-parse</strong></code> <strong class="ky ir">。</strong></li><li id="9470" class="lu lv iq ky b kz md lc me lf mf lj mg ln mh lr lz ma mb mc bi translated"><strong class="ky ir">数据爬虫方法的影响。</strong>我们应该根据数据集用例选择正确的方法。</li><li id="6d01" class="lu lv iq ky b kz md lc me lf mf lj mg ln mh lr lz ma mb mc bi translated">浏览网站时要有耐心。先看<code class="fe ok ol om on b">&lt;script&gt;</code>标签，再看HTML内容。</li></ul><p id="0d21" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">希望文章有帮助。感谢您的阅读！</p><p id="967f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="os">更多内容看</em> <a class="ae kv" href="https://plainenglish.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> <em class="os">说白了就是</em> </strong> </a> <em class="os">。</em></p><p id="35c0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="os">报名参加我们的</em> <a class="ae kv" href="http://newsletter.plainenglish.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> <em class="os">免费每周简讯</em> </strong> </a> <em class="os">。关注我们关于</em> <a class="ae kv" href="https://twitter.com/inPlainEngHQ" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> <em class="os">推特</em> </strong> </a>，<a class="ae kv" href="https://www.linkedin.com/company/inplainenglish/" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir"><em class="os">LinkedIn</em></strong></a><em class="os">，</em><a class="ae kv" href="https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir"><em class="os">YouTube</em></strong></a><em class="os">，</em> <a class="ae kv" href="https://discord.gg/GtDtUAvyhW" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> <em class="os">不和</em></strong></a><strong class="ky ir"><strong class="ky ir"><em class="os">。</em> </strong></strong></p><p id="3bf9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> <em class="os">有兴趣缩放你的软件启动</em> </strong> <em class="os">？检查出</em> <a class="ae kv" href="https://circuit.ooo?utm=publication-post-cta" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> <em class="os">电路</em> </strong> </a> <em class="os">。</em></p></div></div>    
</body>
</html>