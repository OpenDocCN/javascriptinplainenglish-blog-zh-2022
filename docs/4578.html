<html>
<head>
<title>Best Tool for Web Scraping: BeautifulSoup vs. Regex vs. Advanced Web Scrapers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">最佳网络抓取工具:beautiful soup vs . Regex vs . Advanced Web Scrapers</h1>
<blockquote>原文：<a href="https://javascript.plainenglish.io/best-tool-for-web-scraping-beautifulsoup-vs-regex-vs-advanced-web-scrapers-50b8fb92950d?source=collection_archive---------4-----------------------#2022-12-15">https://javascript.plainenglish.io/best-tool-for-web-scraping-beautifulsoup-vs-regex-vs-advanced-web-scrapers-50b8fb92950d?source=collection_archive---------4-----------------------#2022-12-15</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><div class=""><h2 id="1242" class="pw-subtitle-paragraph jk im in bd b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb dk translated">BeautifulSoup、正则表达式或高级web scraper——哪一个是web抓取的最佳工具？使用每种工具深入研究web抓取。</h2></div><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi kc"><img src="../Images/e33f3d89296368f7f522f1e484481d8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3uovzOxyUCj7r0jL"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk">Photo by <a class="ae ks" href="https://unsplash.com/@markusspiske?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Markus Spiske</a> on <a class="ae ks" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="2b2f" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">从市场营销到战略发展，通过web抓取进行数据提取已经成为许多行业出于各种目的的重要需求。web抓取的核心思想是从没有API端点来获取数据的公共网站中提取数据。</p><p id="b183" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">现代开发人员使用许多方法来抓取web，最传统的方法是编写自己的脚本并抓取您需要的内容。因此，开发人员使用像Python和JavaScript这样的编程语言来编写他们的脚本。</p><p id="885b" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">这篇博客文章比较了三种抓取数据的方法:使用DOM解析(通过Python和BeautifulSoup库)、Regex(通过JavaScript)和一个<a class="ae ks" href="https://get.brightdata.com/web-scraper8453" rel="noopener ugc nofollow" target="_blank">高级web抓取工具</a>。我们将研究每种方法及其优缺点，以帮助您决定满足您需求的最佳方法。</p><p id="c780" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">首先，我们将了解如何使用DOM解析来抓取网站。我们开始吧。</p><h1 id="44ac" class="lp lq in bd lr ls lt lu lv lw lx ly lz jt ma ju mb jw mc jx md jz me ka mf mg bi translated">1.使用DOM解析的Web抓取(使用Python/BeautifulSoup)</h1><p id="400c" class="pw-post-body-paragraph kt ku in kv b kw mh jo ky kz mi jr lb lc mj le lf lg mk li lj lk ml lm ln lo ig bi translated">使用DOM遍历抓取网站相对容易，因为有大量的第三方Python和JavaScript库支持我们这样做。让我们从Python开始。</p><h2 id="1065" class="mm lq in bd lr mn mo dn lv mp mq dp lz lc mr ms mb lg mt mu md lk mv mw mf mx bi translated">步骤1:创建一个虚拟环境并安装所需的库。</h2><p id="ef99" class="pw-post-body-paragraph kt ku in kv b kw mh jo ky kz mi jr lb lc mj le lf lg mk li lj lk ml lm ln lo ig bi translated">因为我们将使用第三方依赖项(HTTP请求的请求和DOM遍历的BeautifulSoup)进行抓取，所以最好创建一个虚拟环境。</p><p id="350c" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">执行以下两个命令来创建并激活虚拟环境:</p><pre class="kd ke kf kg gt my mz na bn nb nc bi"><span id="4282" class="nd lq in mz b be ne nf l ng nh">python3 -m venv venv<br/>source venv/bin/activate</span></pre><p id="d58b" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">或者，如果你在Windows上，</p><pre class="kd ke kf kg gt my mz na bn nb nc bi"><span id="e7d6" class="nd lq in mz b be ne nf l ng nh">&gt; python3 -m venv venv<br/>&gt; cd venv/Scripts<br/>&gt; activate</span></pre><p id="11be" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">激活后，虚拟环境将显示在我们的终端。</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi ni"><img src="../Images/6a906d085c42f5c5e13b41ab006ac7a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*aKGgl9gkpeoQioEe"/></div></div></figure><p id="6634" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">要开始web抓取，我们必须使用以下命令在<strong class="kv io"> venv </strong>中安装以下第三方库:</p><pre class="kd ke kf kg gt my mz na bn nb nc bi"><span id="081d" class="nd lq in mz b be ne nf l ng nh">python -m pip install requests<br/>python -m pip install beautifulsoup4</span></pre><h2 id="6a1b" class="mm lq in bd lr mn mo dn lv mp mq dp lz lc mr ms mb lg mt mu md lk mv mw mf mx bi translated">第二步:分析要刮的博客。</h2><p id="42e1" class="pw-post-body-paragraph kt ku in kv b kw mh jo ky kz mi jr lb lc mj le lf lg mk li lj lk ml lm ln lo ig bi translated">这里我们将使用GeeksforGeeks的一个博客来演示实现。我们将选择下面的博客网址开始抓取脚本:<a class="ae ks" href="https://www.geeksforgeeks.org/what-is-web-scraping-and-how-to-use-it/" rel="noopener ugc nofollow" target="_blank">https://www . geeks forgeeks . org/what-is-web-scraping-and-how-to-use-it/</a></p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi nj"><img src="../Images/9fe745921d901c716300b37a4d1e0502.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qzYK6opr0bS9bQLE"/></div></div></figure><p id="fd6e" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">这个博客抓取器将使用一个URL并获取博客中发布的内容列表，然后它将收集文章名称等属性。</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi nk"><img src="../Images/6470dcddbf06bc233bb435a69f01de07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-Ls7jDe5aNjiz1Cr"/></div></div></figure><h2 id="c085" class="mm lq in bd lr mn mo dn lv mp mq dp lz lc mr ms mb lg mt mu md lk mv mw mf mx bi translated">步骤3:实现Scraper</h2><p id="38f7" class="pw-post-body-paragraph kt ku in kv b kw mh jo ky kz mi jr lb lc mj le lf lg mk li lj lk ml lm ln lo ig bi translated">首先，创建一个名为<strong class="kv io"> scraper.py </strong>的Python文件，并添加两个导入，如下所示:</p><pre class="kd ke kf kg gt my mz na bn nb nc bi"><span id="4e10" class="nd lq in mz b be ne nf l ng nh">from bs4 import BeautifulSoup<br/>import requests<br/>import json</span></pre><p id="8482" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">请求库生成一个GET请求来获取博客文章的数据。</p><pre class="kd ke kf kg gt my mz na bn nb nc bi"><span id="b627" class="nd lq in mz b be ne nf l ng nh">blogUrl = “https://www.geeksforgeeks.org/what-is-web-scraping-and-how-to-use-it/"<br/>response = requests.get(blogUrl)</span></pre><p id="46a2" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">然后，必须使用BeautifulSoup的HTML解析器将返回的文本响应解析成HTML。</p><pre class="kd ke kf kg gt my mz na bn nb nc bi"><span id="a274" class="nd lq in mz b be ne nf l ng nh">parsedHtml = BeautifulSoup(response.text, ‘html.parser’)</span></pre><p id="47e3" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">然后，可以通过执行一个<a class="ae ks" href="https://developer.mozilla.org/en-US/docs/Web/API/Document_Object_Model/Introduction" rel="noopener ugc nofollow" target="_blank"> DOM操作</a>提取数据来查询故事。</p><pre class="kd ke kf kg gt my mz na bn nb nc bi"><span id="0743" class="nd lq in mz b be ne nf l ng nh">blogDetails = []<br/>blog = parsedHtml.find(‘article’, class_=’content post-414923 post type-post status-publish format-standard hentry category-guestblogs tag-web-scraping’)<br/>blogTitle = blog.find(‘h1’).text<br/>blogDetails.append({<br/> ‘blogTitle’: blogTitle<br/>})<br/><br/>file = open(‘stories.json’, ‘w’)<br/>file.write(json.dumps(blogDetails))</span></pre><p id="02f7" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">这里，使用<code class="fe nl nm nn mz b">parsedHtml.find(‘div’, class_=’brd_blog_titles’)</code> DOM操作抓取博文，然后相应地捕获所有数据。最后，收集的数据被追加到一个数组中，并写入一个JSON文件。最终结果如下:</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi no"><img src="../Images/864faf10d571ac1dbcfd8e6b6b1cdfac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*mGLWG010GE2U3Taw"/></div></div></figure><p id="d2d3" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">现在，对于web抓取来说，DOM解析有一些优点，也有一些缺点，让我们来看看。</p><h2 id="fe62" class="mm lq in bd lr mn mo dn lv mp mq dp lz lc mr ms mb lg mt mu md lk mv mw mf mx bi translated">使用DOM解析进行Web抓取的利弊</h2><p id="420a" class="pw-post-body-paragraph kt ku in kv b kw mh jo ky kz mi jr lb lc mj le lf lg mk li lj lk ml lm ln lo ig bi translated"><strong class="kv io">优点:</strong></p><ul class=""><li id="f58c" class="np nq in kv b kw kx kz la lc nr lg ns lk nt lo nu nv nw nx bi translated"><strong class="kv io">强大的库和通用性:</strong>这种方式进行网页抓取的最大优势之一就是通用性。例如，Python有几个用于此目的的库，如BeautifulSoup、Scrapy和Selenium。这些已经开发了多年，使得从HTML和XML文档中提取数据、处理cookies、会话和其他web抓取任务变得容易。</li><li id="95da" class="np nq in kv b kw ny kz nz lc oa lg ob lk oc lo nu nv nw nx bi translated"><strong class="kv io">受欢迎程度和活跃社区:</strong> DOM解析是web抓取的首选方法，无论您使用的是Python还是JavaScript，您都可以找到大量的教程、支持论坛和其他资源来帮助您完成web抓取项目。</li></ul><p id="58d9" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated"><strong class="kv io">缺点:</strong></p><ul class=""><li id="4997" class="np nq in kv b kw kx kz la lc nr lg ns lk nt lo nu nv nw nx bi translated"><strong class="kv io">耗费时间和资源的过程:</strong>一次抓取大型网站或多个网站可能是一项耗时且耗费资源的任务。如果我们进行大规模的搜集，我们可能会发现自己在遇到服务器块之前就已经遇到了资源限制。此外，一些网站可能有防止网络抓取的措施，而DOM解析可能无法有效绕过这些措施。<br/>不用说，对于企业和个人开发者来说，这都不理想。但是，如果使用高级的web刮刀，这个问题就解决了(稍后将详细介绍)。</li><li id="d90d" class="np nq in kv b kw ny kz nz lc oa lg ob lk oc lo nu nv nw nx bi translated"><strong class="kv io">抓取结构或布局不断变化的网站时，需要频繁的开发人员干预:</strong>如果我们抓取的网站改变了其布局或结构，我们的脚本可能会中断。这可能需要经常维护我们的网络抓取脚本，以确保它们继续按预期工作。对于个人开发者和企业来说，这可能是一个痛苦的过程。为了避免这种情况，我们可以使用先进的抓取工具来处理结构或布局不断变化的动态网站。如前所述，我们将在本文后面看到更详细的内容。</li><li id="5580" class="np nq in kv b kw ny kz nz lc oa lg ob lk oc lo nu nv nw nx bi translated"><strong class="kv io">数据隐私——道德和法律问题:</strong>网络搜集可能会引发道德和法律问题，这取决于您搜集的网站以及您如何使用所搜集的数据。重要的是要尊重你所浏览网站的服务条款，避免侵犯任何版权或其他知识产权。为了避免这一灰色区域，最好使用符合主要法律法规的刮擦工具或服务，包括新的欧盟数据保护监管框架、GDPR和2018年加州消费者隐私法(CCPA)——尊重行使隐私权的请求。</li></ul><p id="b3a1" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">接下来，我们将使用正则表达式(使用JavaScript)完成web抓取过程。事不宜迟，我们开始吧。</p><h1 id="b940" class="lp lq in bd lr ls lt lu lv lw lx ly lz jt ma ju mb jw mc jx md jz me ka mf mg bi translated">2.使用正则表达式/JavaScript的Web抓取</h1><p id="6719" class="pw-post-body-paragraph kt ku in kv b kw mh jo ky kz mi jr lb lc mj le lf lg mk li lj lk ml lm ln lo ig bi translated">如果我们想在没有任何依赖性的情况下进行web抓取(从而保持我们的脚本轻量级)，我们最好的选择是<a class="ae ks" href="https://en.wikipedia.org/wiki/Regular_expression" rel="noopener ugc nofollow" target="_blank">正则表达式</a>(也就是“正则表达式”)。</p><p id="7e1b" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">这是如何工作的？嗯，HTML是<strong class="kv io">语义</strong>。它是一种使用标签来构建内容的标记语言，因此正则表达式可以很容易地匹配和提取这些标签及其内容。</p><p id="d39a" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">例如，假设我们想要提取所有标题的文本(<h1>、<h2>等)。)在网页上。我们可以使用正则表达式来匹配每个标题的开始和结束标记，并提取中间的文本。我们将在本文中简要介绍这一过程，您将看到这对于从web页面中提取特定数据或创建页面内容的结构化数据表示非常有用。</h2></h1></p><p id="03a6" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">这里，我们将抓取与Python示例相同的<a class="ae ks" href="https://www.geeksforgeeks.org/what-is-web-scraping-and-how-to-use-it/" rel="noopener ugc nofollow" target="_blank">网站</a>。</p><pre class="kd ke kf kg gt my mz na bn nb nc bi"><span id="bc0b" class="nd lq in mz b be ne nf l ng nh">// Define an async function to fetch the page data<br/>async function fetchPageData() {<br/>  // Make an HTTP request to the web page<br/>  const response = await <br/>  fetch(‘https://www.geeksforgeeks.org/what-is-web-scraping-and-how-to-use-it/');<br/>  // Get the HTML content of the page<br/>  const html = await response.text();<br/>  // Use a regular expression to match and extract the headings<br/>  const headingsRegex = /&lt;h[1–6]&gt;(.*?)&lt;\/h[1–6]&gt;/g;<br/>  const headings = html.match(headingsRegex);<br/>  // Return the extracted headings<br/>  return headings;<br/>}</span></pre><p id="cea1" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">总之，正则表达式允许我们从文档中匹配和提取特定的标签和属性，对于解析文档结构(如HTML)非常有用。这对于从网页中提取数据或创建网页内容的结构化表示非常有用。</p><p id="f08d" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">正如我们所见，与使用BeautifulSoup这样的外部库进行DOM解析相比，这是一种相对简单的方法。然而，在使用正则表达式或正则表达式进行web抓取之前，理解利弊是至关重要的。</p><p id="a24b" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">我们来看看利弊。</p><h2 id="9002" class="mm lq in bd lr mn mo dn lv mp mq dp lz lc mr ms mb lg mt mu md lk mv mw mf mx bi translated">正则表达式/JavaScript网络抓取的利与弊</h2><p id="ff91" class="pw-post-body-paragraph kt ku in kv b kw mh jo ky kz mi jr lb lc mj le lf lg mk li lj lk ml lm ln lo ig bi translated"><strong class="kv io">优点</strong></p><ul class=""><li id="535f" class="np nq in kv b kw kx kz la lc nr lg ns lk nt lo nu nv nw nx bi translated"><strong class="kv io">提取精确信息:</strong>使用regex进行网页抓取的最大优势之一是，它允许我们从网页中提取非常具体和精确的信息。使用regex，我们可以定义一个模式，只匹配我们正在寻找的文本，而忽略页面上的其他内容。这在处理包含大量不相关或嘈杂信息的网页时特别有用。在上面的例子中，我们使用这种方法从页面中提取标题，忽略其余的数据。</li><li id="f4cd" class="np nq in kv b kw ny kz nz lc oa lg ob lk oc lo nu nv nw nx bi translated">regex的另一个优点是它得到了广泛的支持，可以在许多不同的编程语言中使用，包括JavaScript。这意味着如果我们熟悉regex，我们可以在我们的web抓取项目中使用它，而不必学习新的语言或工具。</li></ul><p id="42be" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">然而，使用正则表达式进行网页抓取也有一些潜在的缺点。</p><h2 id="d017" class="mm lq in bd lr mn mo dn lv mp mq dp lz lc mr ms mb lg mt mu md lk mv mw mf mx bi translated">骗局</h2><ul class=""><li id="ea3e" class="np nq in kv b kw mh kz mi lc od lg oe lk of lo nu nv nw nx bi translated"><strong class="kv io">难以编写和调试:</strong>正则表达式模式可能很复杂，难以阅读，并且很容易出错，导致我们的模式与我们要寻找的文本不匹配。此外，regex可能运行缓慢，尤其是在应用于大量文本时。</li><li id="1b76" class="np nq in kv b kw ny kz nz lc oa lg ob lk oc lo nu nv nw nx bi translated"><strong class="kv io">可呆板:</strong>可脆可呆板。因为正则表达式模式非常特殊，如果网页的结构稍有变化，它们很容易被破坏。这意味着，随着网页的不断变化，我们可能需要不断地更新和维护我们的正则表达式模式。</li></ul><p id="57fd" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">总的来说，使用正则表达式进行网页抓取的利弊将取决于我们的具体情况和需求。如果我们需要从网页中提取非常具体的信息，并且习惯使用regex，那么它可能是一个有用的工具。</p><p id="791a" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">然而，如果我们正在处理大量的文本或者需要能够适应变化的网页结构，那么其他的web抓取方法可能更合适。这就是Bright Data的<a class="ae ks" href="https://get.brightdata.com/web-scraper8453" rel="noopener ugc nofollow" target="_blank"> <strong class="kv io"> Web Scraper IDE </strong> </a>的用武之地。我们将在下一节中找到关于这个工具的更多信息。</p><h1 id="252f" class="lp lq in bd lr ls lt lu lv lw lx ly lz jt ma ju mb jw mc jx md jz me ka mf mg bi translated">3.使用Bright Data的Web Scraper IDE进行网页抓取</h1><p id="61d8" class="pw-post-body-paragraph kt ku in kv b kw mh jo ky kz mi jr lb lc mj le lf lg mk li lj lk ml lm ln lo ig bi translated">我们可以不使用上面讨论的所有编码方法和技术，而是使用高级的web抓取工具，如Bright Data的Web Scraper IDE。这个强大的工具允许我们抓取数据并以任何标准格式存储。</p><h2 id="f102" class="mm lq in bd lr mn mo dn lv mp mq dp lz lc mr ms mb lg mt mu md lk mv mw mf mx bi translated">步骤1:设置帐户以使用Web Scraper IDE</h2><p id="c110" class="pw-post-body-paragraph kt ku in kv b kw mh jo ky kz mi jr lb lc mj le lf lg mk li lj lk ml lm ln lo ig bi translated">首先，进入光明数据的<a class="ae ks" href="https://get.brightdata.com/web-scraper8453" rel="noopener ugc nofollow" target="_blank"><strong class="kv io">Web Scraper IDE</strong></a>，点击‘开始免费试用’。然后我们填写表格，填写我们的基本信息，并注册Bright Data。</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi nk"><img src="../Images/8cd21c848ed6fcd010c195bd436eb189.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*CQOj_eFHgdgGMnIx"/></div></div></figure><p id="d3d5" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">这里我们需要给出我们的组织ID来注册并开始使用IDE。</p><p id="d689" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">接下来，我们将使用我的详细信息创建一个帐户，并演示如何使用Bright Data IDE收集数据。</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi og"><img src="../Images/578939d863524d1b5e8eb5f210dfe9b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*YwwBR_K-DaTtd_wd"/></div></div></figure><h2 id="f296" class="mm lq in bd lr mn mo dn lv mp mq dp lz lc mr ms mb lg mt mu md lk mv mw mf mx bi translated">步骤2:访问IDE</h2><p id="80af" class="pw-post-body-paragraph kt ku in kv b kw mh jo ky kz mi jr lb lc mj le lf lg mk li lj lk ml lm ln lo ig bi translated">注册后，转到Web数据平台页面，在那里我们可以找到许多有用的链接来检查数据集市场、请求自定义数据集、检查Bright Data insights以及访问IDE。</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi oh"><img src="../Images/2b467713d5a9a2c27b84137cafbb660d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*e5RGkqtvg-8W5xqZ"/></div></div></figure><p id="5543" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">接下来，选择Web Scraper IDE卡上的“开始”按钮，并选择一个模板开始。这里，我们将选择一个Twitter标签搜索。</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi oi"><img src="../Images/063811031854b354efe923e1d6ab5d3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*w1WukLZTZbVdhFn-"/></div></div></figure><h2 id="b020" class="mm lq in bd lr mn mo dn lv mp mq dp lz lc mr ms mb lg mt mu md lk mv mw mf mx bi translated">步骤3:了解IDE并收集数据</h2><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi nk"><img src="../Images/e3be1103e0cdf825cb9281b251af9d1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EQvMKMCSJhfT2V7p"/></div></div></figure><p id="aef5" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">IDE是在JavaScript之上开发的，你可以根据自己的需求编写代码。它为您提供了JavaScript的超集函数和命令，并通过提供简化的开发人员体验缓解了web抓取的许多棘手问题。</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi oj"><img src="../Images/50d94b86bb26f2b983e0930d1541b8e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Gp0aCTtxPGL5QI2Q"/></div></div></figure><p id="61a1" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">IDE本身由三个主要部分组成，它们是:</p><ol class=""><li id="7eac" class="np nq in kv b kw kx kz la lc nr lg ns lk nt lo ok nv nw nx bi translated"><strong class="kv io">交互代码</strong>:</li></ol><p id="0483" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">这是我们配置铲运机的地方。一旦我们选择了一个模板，我们可以让这些设置保持不变。但是，如果我们正在编写自己的脚本，IDE会为我们提供详细、有用的注释，让我们知道每个选项的作用，以及我们为什么要更改它们。举个例子，</p><pre class="kd ke kf kg gt my mz na bn nb nc bi"><span id="2443" class="nd lq in mz b be ne nf l ng nh">//Max Time of collection (4.5m + then 30sec to collect result)<br/>let collection_time = new Date(Date.now() + 4.5 * 60000)</span></pre><p id="311e" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated"><code class="fe nl nm nn mz b">Date.now()</code>返回一个以毫秒为单位的值，因此，如果我们希望收集器收集最多2分钟的数据，我们可以将其改为<code class="fe nl nm nn mz b">new Date(Date.now() + 2 * 60000)</code>。</p><p id="cdea" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">此外，我们可以通过配置一个忽略数组来过滤导航到不需要的页面。</p><pre class="kd ke kf kg gt my mz na bn nb nc bi"><span id="86ad" class="nd lq in mz b be ne nf l ng nh">try {<br/>  wait_network_idle({ignore:[/accounts.google.com/, /twitter.com\/sw.js/, /twitter.com\/i\/jot/]})<br/>} catch (e) {}</span></pre><p id="572e" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated"><strong class="kv io"> 2。解析器代码</strong>:</p><p id="dad8" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">提取HTML只是第一步。在这一节中，我们编写代码，将提取的数据解析和净化成我们想要的结构。我们在交互代码中收集的每个变量都会调用这个函数。</p><p id="829f" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">例如，如果我们在交互代码中收集了这些…</p><pre class="kd ke kf kg gt my mz na bn nb nc bi"><span id="ffa5" class="nd lq in mz b be ne nf l ng nh">// call parse() to get the data<br/>// then call collect() to add a record to your final dataset<br/>let data = parse();<br/>collect({<br/>  url: new URL(location.href),<br/>  title: data.title,<br/>  links: data.links,<br/>});</span></pre><p id="d36a" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">…我们将在解析器代码中对这些变量进行整理(去掉尾随空格)和添加结构(将所有提取的链接添加到一个数组中，而不是明文)。</p><pre class="kd ke kf kg gt my mz na bn nb nc bi"><span id="8eec" class="nd lq in mz b be ne nf l ng nh">// Code that will parse page HTML into structured data.<br/>// Use parse() in interaction code to read this data.<br/>return {<br/>  title: $(‘h1’).text().trim(),<br/>  links: $(‘a’).toArray().map(e=&gt;new URL($(e).attr(‘href’))),<br/>};</span></pre><p id="291e" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">3.<strong class="kv io">用户交互单元</strong>:</p><p id="219f" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">在这里，我们可以:</p><ul class=""><li id="e3a9" class="np nq in kv b kw kx kz la lc nr lg ns lk nt lo nu nv nw nx bi translated"><strong class="kv io"> Input </strong> —管理我们的输入(在本例中，这是我们放置所关注的标签的地方)。正如所料，我们在这里的输入将被插入到我们实际的抓取代码中。单击预览进行测试。</li></ul><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi ol"><img src="../Images/74c44ae862f17f780c6a31c2dee4d446.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*q4-mxUN28zmWd5Aq"/></div></div></figure><ul class=""><li id="ef02" class="np nq in kv b kw kx kz la lc nr lg ns lk nt lo nu nv nw nx bi translated"><strong class="kv io">运行日志</strong> —我们可以通过查看运行日志来检查作业状态。</li></ul><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi om"><img src="../Images/3fa8724e65b93d7a38684595c7ff1435.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*805GRcFNHAjh83R7"/></div></div></figure><ul class=""><li id="2ce1" class="np nq in kv b kw kx kz la lc nr lg ns lk nt lo nu nv nw nx bi translated"><strong class="kv io">浏览器控制台</strong> —该窗口是内置的浏览器控制台，显示运行期间发生的任何错误。</li></ul><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi nk"><img src="../Images/53848407387f504c62a946c9105176fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*MpoO0zkBavBBMpe_"/></div></div></figure><ul class=""><li id="6c3b" class="np nq in kv b kw kx kz la lc nr lg ns lk nt lo nu nv nw nx bi translated"><strong class="kv io">浏览器网络</strong> —在这里，我们可以监控通过IDE传递的所有请求。</li></ul><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi nk"><img src="../Images/85c800e785b26703690d1db4f9d0d0cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*DF2A-NJCQWtqGG_9"/></div></div></figure><ul class=""><li id="cd8d" class="np nq in kv b kw kx kz la lc nr lg ns lk nt lo nu nv nw nx bi translated"><strong class="kv io">最后一个错误</strong> —在这里，我们可以监控在完成刮削任务后是否出现任何错误。</li></ul><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi on"><img src="../Images/1185274f9a0753d9aebecd6a6d304572.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*cQzdt00RmKURxt4V"/></div></div></figure><ul class=""><li id="fd6a" class="np nq in kv b kw kx kz la lc nr lg ns lk nt lo nu nv nw nx bi translated"><strong class="kv io">输出</strong> —我们可以看到抓取的结果并下载数据集。</li></ul><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi nk"><img src="../Images/fcde29563db8d1d39c3c5370379c5e2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Gen7jJgmH6uLfx75"/></div></div></figure><p id="c22d" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">那是一个包裹。接下来，我们将看看这个过程的利与弊。</p><h2 id="d924" class="mm lq in bd lr mn mo dn lv mp mq dp lz lc mr ms mb lg mt mu md lk mv mw mf mx bi translated">使用Bright Data的Web Scraper IDE进行Web抓取的利弊</h2><p id="a676" class="pw-post-body-paragraph kt ku in kv b kw mh jo ky kz mi jr lb lc mj le lf lg mk li lj lk ml lm ln lo ig bi translated"><strong class="kv io">优点:</strong></p><ul class=""><li id="c40d" class="np nq in kv b kw kx kz la lc nr lg ns lk nt lo nu nv nw nx bi translated">该IDE可通过Bright Data的网站访问，使其易于立即启动。它不需要任何内部数据收集基础设施。</li><li id="cf91" class="np nq in kv b kw ny kz nz lc oa lg ob lk oc lo nu nv nw nx bi translated">基于Bright Data的<a class="ae ks" href="https://get.brightdata.com/proxy-types7488" rel="noopener ugc nofollow" target="_blank">代理基础设施</a>，实现可扩展性和99.9%的准确性。</li><li id="cca7" class="np nq in kv b kw ny kz nz lc oa lg ob lk oc lo nu nv nw nx bi translated">使用<a class="ae ks" href="https://get.brightdata.com/web-unlocker9963" rel="noopener ugc nofollow" target="_blank">解锁器</a>基础设施，有助于克服基于验证码、IP和设备指纹的拦截(要更详细地深入了解解锁器基础设施如何帮助克服网站拦截，请访问<a class="ae ks" href="https://get.brightdata.com/web-unlocker-enables-better-fingerprinting-auto-unlocking-and-captcha-solving" rel="noopener ugc nofollow" target="_blank"> <strong class="kv io">此处</strong> </a>)。</li><li id="b070" class="np nq in kv b kw ny kz nz lc oa lg ob lk oc lo nu nv nw nx bi translated">为我们提供了各种数据丰富的网站的现成模板，以及基于JavaScript构建的有用函数和命令，帮助我们编写scraper，而无需手动编写所有代码。</li><li id="4fc1" class="np nq in kv b kw ny kz nz lc oa lg ob lk oc lo nu nv nw nx bi translated">与传统的DOM解析或使用regex的抓取方法不同，我们可以从动态网站中提取数据，因为IDE支持开箱即用的浏览器模拟，从而省去我们配置Selenium的麻烦。</li><li id="b253" class="np nq in kv b kw ny kz nz lc oa lg ob lk oc lo nu nv nw nx bi translated">在典型的web抓取应用程序中，每当网站更新时，我们都需要更新我们的脚本。然而，使用Bright Data的IDE，我们可以从任何公开可用的网站提取数据，而不用担心，因为它是一个托管服务，可以自动为我们更新模板。</li><li id="8652" class="np nq in kv b kw ny kz nz lc oa lg ob lk oc lo nu nv nw nx bi translated">光明数据致力于遵守数据保护要求，包括GDPR和CCPA。</li><li id="0836" class="np nq in kv b kw ny kz nz lc oa lg ob lk oc lo nu nv nw nx bi translated">虽然其他方法确实有广泛的社区支持，但如果我们遇到问题，我们仍然需要花时间在网上搜索资源。Bright Data提供24/7实时支持，因此我们不必浪费时间在海量信息中筛选，只为找到解决问题的正确方案。</li></ul><p id="45b4" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated"><strong class="kv io">缺点:</strong></p><ul class=""><li id="82d5" class="np nq in kv b kw kx kz la lc nr lg ns lk nt lo nu nv nw nx bi translated">有一个免费试用，我们需要在它结束后为明亮的数据付费。</li><li id="e76d" class="np nq in kv b kw ny kz nz lc oa lg ob lk oc lo nu nv nw nx bi translated">作为所有方法的共同问题，只能提取公开可用的数据。</li></ul><h1 id="ea07" class="lp lq in bd lr ls lt lu lv lw lx ly lz jt ma ju mb jw mc jx md jz me ka mf mg bi translated">网页抓取最好的方法是什么？</h1><p id="2de9" class="pw-post-body-paragraph kt ku in kv b kw mh jo ky kz mi jr lb lc mj le lf lg mk li lj lk ml lm ln lo ig bi translated">正如我们上面讨论的，DOM解析是首选的web抓取方法，但是它也有问题。它不可扩展，可能会有网站获得新更新的情况，在这种情况下，我们可能会重写超过90%的脚本。</p><p id="b7b1" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">正则表达式是一种非常规的策略，可以很好地为我们服务，它们使我们的脚本轻量级，可以在任何地方部署。然而，正则表达式是出了名的挑剔和难以编写，而且，如果站点的结构/布局改变，它们也会崩溃。</p><p id="4487" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">除了这些方法，那么，考虑一个更稳定的刮擦解决方案，如<a class="ae ks" href="https://get.brightdata.com/web-scraper8453" rel="noopener ugc nofollow" target="_blank"> <strong class="kv io"> Web Scraper IDE </strong> </a>当扩展时。要习惯光明数据这样的工具，不如选择免费试用的工具来试试，不浪费你的钱。</p><p id="f616" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">考虑到以上所有方法，您可以根据自己的需求决定选择什么。</p><p id="ea15" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated"><strong class="kv io"> <em class="oo">原文由</em> </strong> <a class="op oq ep" href="https://medium.com/u/6d47b99e463c?source=post_page-----50b8fb92950d--------------------------------" rel="noopener" target="_blank"> <strong class="kv io"> <em class="oo">查鲁卡</em> </strong> </a> <strong class="kv io"> <em class="oo">写成。</em> </strong></p></div></div>    
</body>
</html>